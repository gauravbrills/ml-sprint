{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.8168373151308305\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy\n",
    "numpy.random.seed(42)\n",
    "\n",
    "\n",
    "### The words (features) and authors (labels), already largely processed.\n",
    "### These files should have been created from the previous (Lesson 10)\n",
    "### mini-project.\n",
    "words_file = \"../text_learning/your_word_data.pkl\" \n",
    "authors_file = \"../text_learning/your_email_authors.pkl\"\n",
    "word_data = pickle.load( open(words_file, \"rb\"))\n",
    "authors = pickle.load( open(authors_file, \"rb\") )\n",
    "\n",
    "\n",
    "\n",
    "### test_size is the percentage of events assigned to the test set (the\n",
    "### remainder go into training)\n",
    "### feature matrices changed to dense representations for compatibility with\n",
    "### classifier functions in versions 0.15.2 and earlier\n",
    "from sklearn.model_selection import train_test_split\n",
    "features_train, features_test, labels_train, labels_test = train_test_split(word_data, authors, test_size=0.1, random_state=42)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                             stop_words='english')\n",
    "features_train = vectorizer.fit_transform(features_train)\n",
    "features_test  = vectorizer.transform(features_test).toarray()\n",
    "\n",
    "\n",
    "### a classic way to overfit is to use a small number\n",
    "### of data points and a large number of features;\n",
    "### train on only 150 events to put ourselves in this regime\n",
    "features_train = features_train[:150].toarray()\n",
    "labels_train   = labels_train[:150]\n",
    "\n",
    "\n",
    "\n",
    "### your code goes here\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(features_train, labels_train)\n",
    "print (\"accuracy:\", clf.score(features_test, labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37861\n",
      "index: 21323\n",
      "importance: 0.36363636363636365\n",
      "problem word: houectect\n",
      "1 feature no.21323 (0.36363636363636365)\n",
      "2 feature no.18849 (0.1869272434489826)\n",
      "3 feature no.11975 (0.10537857900318125)\n",
      "4 feature no.22546 (0.08406920992286854)\n",
      "5 feature no.29690 (0.047580525890385035)\n",
      "6 feature no.16267 (0.047407407407407405)\n",
      "7 feature no.18095 (0.04266666666666666)\n",
      "8 feature no.13080 (0.026280193236714978)\n",
      "9 feature no.25675 (0.02552933057280883)\n",
      "10 feature no.24320 (0.02481019450033535)\n"
     ]
    }
   ],
   "source": [
    "problemWordIndices = []\n",
    "\n",
    "importances = clf.feature_importances_\n",
    "print(len(importances))\n",
    "for index in range(len(importances)):\n",
    "    if importances[index] > 0.2:\n",
    "        print (\"index:\", index)\n",
    "        problemWordIndices.append(index)\n",
    "        print (\"importance:\", importances[index])\n",
    "\n",
    "for index in problemWordIndices:\n",
    "    print (\"problem word:\", vectorizer.get_feature_names()[index] )       \n",
    "\n",
    "import numpy as np\n",
    "indices = np.argsort(importances)[::-1]\n",
    "for i in range(10):\n",
    "    print (\"{} feature no.{} ({})\".format(i+1,indices[i],importances[indices[i]])  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
